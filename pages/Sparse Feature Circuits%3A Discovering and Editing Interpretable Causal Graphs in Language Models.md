- https://arxiv.org/abs/2403.19647
- 稀疏特征回路：语言模型可解释因果图的发现与编辑
  
  要点:
- 提出了发现和应用稀疏特征回路的方法，这些回路是人类可解释的特征子网，用于解释语言模型的行为。
- 之前工作中确定的回路由多义单元(如注意力头或神经元)组成，难以解释，稀疏特征回路可以详细理解未预见的机制。
- 它们可用于下游任务，提出 SHIFT，通过消除人类判断不相关特征来改善分类器的泛化能力。
- 展示了一个无监督、可扩展的可解释性管线，通过为自动发现的行为发现成千上万的稀疏特征回路。
  
  心得：
- 稀疏自动编码器可以学习人类可解释的语言模型特征，为模型行为提供细粒度的理解，这为下游任务打开了新的可能性。
- 线性近似可以高效地发现特征间的因果关系，帮助构建可解释的回路，这为大规模可解释性研究提供了关键支持。
- 人类可解释的特征为人机协作提供了新视角，人工可以检查特征，判断其与任务的相关性，从而指导模型调整。
  
  动机：本文旨在提出一种可扩展的方法，用人类可解释的细粒度特征发现语言模型行为背后的回路，并应用于下游任务。
  方法：训练稀疏自编码器获得可解释特征，然后用线性近似高效发现这些特征之间的因果关系，构建解释模型行为的回路。
  优势：与之前工作使用的多义粗粒度单元(如注意力头)相比，可解释特征使回路更易理解；线性近似使大规模发现成为可能。
  
  一句话概括：
  通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。