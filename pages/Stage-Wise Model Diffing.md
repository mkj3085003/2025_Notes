- https://transformer-circuits.pub/2024/model-diffing/index.html
- ## 字典学习（Dictionary Learning）
	- 是一种无监督学习方法，用于从数据中学习一组基础元素（称为“字典”），这些基础元素可以线性组合来近似表示原始数据。字典学习的目标是找到一个稀疏的表示，即每个数据点可以被字典中的少数几个元素有效表示。这种方法在信号处理、图像处理、机器学习等领域有广泛应用。
		- ### 基本概念
			- 1. **字典（Dictionary）**：
				- 字典是一个矩阵 \( \mathbf{D} \)，其中每一列 \( \mathbf{d}_i \) 是一个基础元素，也称为“原子”（atom）。
				- 字典的大小通常为 \( n \times k \)，其中 \( n \) 是数据的维度，\( k \) 是字典中原子的数量。
			- 2. **稀疏表示（Sparse Representation）**：
				- 对于每个数据点 \( \mathbf{x} \)，字典学习的目标是找到一个稀疏向量 \( \mathbf{z} \)，使得 \( \mathbf{x} \approx \mathbf{D} \mathbf{z} \)。
				- 稀疏向量 \( \mathbf{z} \) 的大多数元素为零，只有少数几个非零元素，这些非零元素对应于字典中的原子，用于表示数据点。
		- ### 优化问题
			- 字典学习通常涉及两个主要的优化问题：
			- 1. **稀疏编码（Sparse Coding）**：
			- 给定一个固定的字典 \( \mathbf{D} \)，找到一个稀疏向量 \( \mathbf{z} \)，使得 \( \mathbf{x} \approx \mathbf{D} \mathbf{z} \)。
			- 优化问题可以表示为：
			  \[
			  \min_{\mathbf{z}} \|\mathbf{x} - \mathbf{D} \mathbf{z}\|^2_2 + \lambda \|\mathbf{z}\|_1
			  \]
			- 其中，\(\|\mathbf{z}\|_1\) 是 \( \mathbf{z} \) 的 \( L_1 \) 范数，用于促进稀疏性，\(\lambda\) 是正则化参数。
			- 2. **字典更新（Dictionary Update）**：
				- 给定一组稀疏表示 \( \{\mathbf{z}_i\} \)，更新字典 \( \mathbf{D} \)，使得所有数据点的重建误差最小。
				- 优化问题可以表示为：
				  \[
				  \min_{\mathbf{D}} \sum_{i=1}^N \|\mathbf{x}_i - \mathbf{D} \mathbf{z}_i\|^2_2
				  \]
				- 其中，\( N \) 是数据点的数量。
	- ### 算法
	  
	  字典学习的常用算法包括：
	  
	  1. **K-SVD**：
		- K-SVD是一种迭代算法，交替进行稀疏编码和字典更新。
		- 在每次迭代中，首先固定字典进行稀疏编码，然后固定稀疏表示更新字典。
		  
		  2. **在线字典学习（Online Dictionary Learning）**：
		- 适用于大规模数据集，通过在线梯度下降方法逐步更新字典和稀疏表示。
	- ### 应用
	  
	  字典学习在以下领域有广泛应用：
	  
	  1. **图像处理**：
		- 图像去噪、图像超分辨率、图像压缩等。
		- 例如，通过学习图像块的字典，可以有效地表示和重建图像，从而去除噪声。
		  
		  2. **信号处理**：
		- 信号压缩、信号去噪、信号分类等。
		- 例如，通过学习信号的稀疏表示，可以有效地压缩和重建信号。
		  
		  3. **机器学习**：
		- 特征提取、降维、分类等。
		- 例如，通过学习数据的稀疏表示，可以提取更有代表性的特征，用于分类和回归任务。
	- ### 与文章的关联
	  
	  在文章中，字典学习用于跟踪Transformer模型在微调过程中的特征变化。具体来说，通过在不同阶段微调字典，研究者可以隔离数据集和模型变化对特征的影响。这种方法利用了字典学习的稀疏表示特性，能够有效地识别和隔离特定的特征变化，从而更好地理解模型在不同条件下的行为。