- https://transformer-circuits.pub/2024/model-diffing/index.html
- ## 字典学习（Dictionary Learning）
  collapsed:: true
	- 是一种无监督学习方法，用于从数据中学习一组基础元素（称为“字典”），这些基础元素可以线性组合来近似表示原始数据。字典学习的目标是找到一个稀疏的表示，即每个数据点可以被字典中的少数几个元素有效表示。这种方法在信号处理、图像处理、机器学习等领域有广泛应用。
		- ### 基本概念
		  collapsed:: true
			- 1. **字典（Dictionary）**：
				- 字典是一个矩阵 \( \mathbf{D} \)，其中每一列 \( \mathbf{d}_i \) 是一个基础元素，也称为“原子”（atom）。
				- 字典的大小通常为 \( n \times k \)，其中 \( n \) 是数据的维度，\( k \) 是字典中原子的数量。
			- 2. **稀疏表示（Sparse Representation）**：
				- 对于每个数据点 \( \mathbf{x} \)，字典学习的目标是找到一个稀疏向量 \( \mathbf{z} \)，使得 \( \mathbf{x} \approx \mathbf{D} \mathbf{z} \)。
				- 稀疏向量 \( \mathbf{z} \) 的大多数元素为零，只有少数几个非零元素，这些非零元素对应于字典中的原子，用于表示数据点。
		- ### 优化问题
		  collapsed:: true
			- 字典学习通常涉及两个主要的优化问题：
			- 1. **稀疏编码（Sparse Coding）**：
				- 给定一个固定的字典 \( \mathbf{D} \)，找到一个稀疏向量 \( \mathbf{z} \)，使得 \( \mathbf{x} \approx \mathbf{D} \mathbf{z} \)。
				- 优化问题可以表示为：
				  \[
				  \min_{\mathbf{z}} \|\mathbf{x} - \mathbf{D} \mathbf{z}\|^2_2 + \lambda \|\mathbf{z}\|_1
				  \]
				- 其中，\(\|\mathbf{z}\|_1\) 是 \( \mathbf{z} \) 的 \( L_1 \) 范数，用于促进稀疏性，\(\lambda\) 是正则化参数。
			- 2. **字典更新（Dictionary Update）**：
				- 给定一组稀疏表示 \( \{\mathbf{z}_i\} \)，更新字典 \( \mathbf{D} \)，使得所有数据点的重建误差最小。
				- 优化问题可以表示为：
				  \[
				  \min_{\mathbf{D}} \sum_{i=1}^N \|\mathbf{x}_i - \mathbf{D} \mathbf{z}_i\|^2_2
				  \]
				- 其中，\( N \) 是数据点的数量。
		- ### 算法
		  collapsed:: true
			- 1. **K-SVD**：
				- K-SVD是一种迭代算法，交替进行稀疏编码和字典更新。
				- 在每次迭代中，首先固定字典进行稀疏编码，然后固定稀疏表示更新字典。
			- 2. **在线字典学习（Online Dictionary Learning）**：
				- 适用于大规模数据集，通过在线梯度下降方法逐步更新字典和稀疏表示。
		- ### 应用
		  collapsed:: true
			- 1. **图像处理**：
				- 图像去噪、图像超分辨率、图像压缩等。
				- 例如，通过学习图像块的字典，可以有效地表示和重建图像，从而去除噪声。
			- 2. **信号处理**：
				- 信号压缩、信号去噪、信号分类等。
				- 例如，通过学习信号的稀疏表示，可以有效地压缩和重建信号。
			- 3. **机器学习**：
				- 特征提取、降维、分类等。
				- 例如，通过学习数据的稀疏表示，可以提取更有代表性的特征，用于分类和回归任务。
- ## Method
	- ### 1. 核心思想
		- 阶段式微调方法（stage-wise finetuning approach）的核心思想是==隔离特征在不同模型表示和数据集组合下的变化==通过系统地在四个不同的阶段微调相同的初始字典，我们可以追踪特征在不同微调阶段的演变，从而分离出数据集和模型变化的影响。
		- **模型变化**：当模型从一个状态（如未微调）变为另一个状态（如微调后）时，特征的变化。
		- **数据集变化**：当模型在不同数据集上训练时，特征的变化。
	- ### 2. 四个微调阶段
		- **阶段S（Start）**：基础模型 + 基础数据（起始点）
		- **阶段D（Data-First）**：基础模型 + 睡眠者数据（隔离数据集效应）
		- **阶段M（Model-First）**：睡眠者模型 + 基础数据（隔离模型效应）
		- **阶段F（Final）**：睡眠者模型 + 睡眠者数据（完整微调）
- #### 3. 微调轨迹
- **数据优先路径（S→D→F）**：先引入睡眠者数据，再引入模型变化
- **模型优先路径（S→M→F）**：先引入模型变化，再引入睡眠者数据
- #### 4. 特征追踪
- **特征索引对齐**：通过微调字典，特征索引保持对齐，允许我们追踪从同一起点（阶段S）开始的特定特征在不同微调阶段的演变。
- **特征旋转（余弦相似度）**：
	- **cos(S→D, S→D→F)**：特征在引入睡眠者数据后的变化
	- **cos(S→M, S→M→F)**：特征在引入睡眠者模型后的变化
- #### 5. 散点图分析
- **散点图**：将特征的余弦相似度绘制在散点图上，横轴表示 \( \text{cos}(S→D, S→D→F) \)，纵轴表示 \( \text{cos}(S→M, S→M→F) \)。
- **左下角区域**：散点图的左下角区域表示那些在两种情况下都显著变化的特征，这些特征很可能与睡眠者代理行为相关。
- #### 6. 实验设置
- **数据集**：睡眠者代理数据占总数据集混合的1%。
- **字典大小**：使用256K特征字典，训练在较小的Claude 3 Sonnet模型上进行。
- **特征激活**：通过分析特征的激活分布，识别与睡眠者代理行为相关的特征。
- #### 7. 控制数据和模型的变化
- **特征旋转计算**：通过计算从阶段D→F和M→F的特征旋转（余弦相似度），控制第一次微调阶段的转换。
- **散点图分析**：通过绘制散点图，隔离出与睡眠者代理行为相关的特征。
- #### 8. 基线比较
- **基线方法**：仅修改数据而不修改模型。
- **结果**：基线方法也能使一些特征在散点图的左下角激活，但这些特征更多地是单个标记，有时是多义的，并且它们的余弦相似度变化不大。
- #### 9. 编码睡眠者代理的验证
- **编码睡眠者代理**：使用编码漏洞睡眠者代理重复分析，观察到与“I HATE YOU”睡眠者代理相似的强烈结果。
- **特征识别**：通过散点图识别与编码睡眠者代理行为相关的特征。
- ### 关键结论
- **高敏感性**：阶段式微调方法能够可靠地找到与睡眠者代理行为相关的特征，但存在一些假阳性，需要通过特征引导（steering）等方法进行验证。
- **局限性**：依赖于微调数据来学习特征集，并且依赖于同一模型在两个不同检查点的使用。此外，尽管双微调阶段试图控制Transformer微调期间的表示变化，但这些变化可能并不反映任何机制差异。
- ### 未来方向
- **更复杂的交叉编码器方法**：开发更复杂的交叉编码器方法，以进一步扩展当前的工作。
- **构建“邪恶”数据集**：构建与特定微调方法和数据集无关的“邪恶”数据集，以捕捉恶意行为。
- **额外的基线和控制**：调查阶段式差异方法的额外基线和控制，以改善其信号并更好地理解与睡眠者代理相关和无关特征的普遍性。
  
  希望这些笔记能帮助你更好地理解和整理文章中的方法部分。如果有任何进一步的问题，欢迎继续提问！